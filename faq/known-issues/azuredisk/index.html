<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.61.0"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/azuredisk-csi-driver/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/azuredisk-csi-driver/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/azuredisk-csi-driver/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/azuredisk-csi-driver/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/azuredisk-csi-driver/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/azuredisk-csi-driver/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/azuredisk-csi-driver/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/azuredisk-csi-driver/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/azuredisk-csi-driver/favicons/android-192x192.png sizes=192x192><title>AzureDisk CSI Driver Known Issues | AzureDisk CSI Driver</title><meta property="og:title" content="AzureDisk CSI Driver Known Issues"><meta property="og:description" content="azure disk plugin known issues  Recommended stable version for azure disk 1. disk attach error 2. disk unavailable after attach/detach a data disk on a node 3. Azure disk support on Sovereign Cloud 4. Time cost for Azure Disk PVC mount 5. Azure disk PVC Multi-Attach error, makes disk mount very slow or mount failure forever 6. WaitForAttach failed for azure disk: parsing &ldquo;/dev/disk/azure/scsi1/lun1&rdquo;: invalid syntax 7. uid and gid setting in azure disk 8."><meta property="og:type" content="article"><meta property="og:url" content="https://Sakuralbj.github.io/azuredisk-csi-driver/faq/known-issues/azuredisk/"><meta property="article:modified_time" content="2020-08-26T15:05:57+08:00"><meta property="og:site_name" content="AzureDisk CSI Driver"><meta itemprop=name content="AzureDisk CSI Driver Known Issues"><meta itemprop=description content="azure disk plugin known issues  Recommended stable version for azure disk 1. disk attach error 2. disk unavailable after attach/detach a data disk on a node 3. Azure disk support on Sovereign Cloud 4. Time cost for Azure Disk PVC mount 5. Azure disk PVC Multi-Attach error, makes disk mount very slow or mount failure forever 6. WaitForAttach failed for azure disk: parsing &ldquo;/dev/disk/azure/scsi1/lun1&rdquo;: invalid syntax 7. uid and gid setting in azure disk 8."><meta itemprop=dateModified content="2020-08-26T15:05:57+08:00"><meta itemprop=wordCount content="2790"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="AzureDisk CSI Driver Known Issues"><meta name=twitter:description content="azure disk plugin known issues  Recommended stable version for azure disk 1. disk attach error 2. disk unavailable after attach/detach a data disk on a node 3. Azure disk support on Sovereign Cloud 4. Time cost for Azure Disk PVC mount 5. Azure disk PVC Multi-Attach error, makes disk mount very slow or mount failure forever 6. WaitForAttach failed for azure disk: parsing &ldquo;/dev/disk/azure/scsi1/lun1&rdquo;: invalid syntax 7. uid and gid setting in azure disk 8."><link rel=preload href=/azuredisk-csi-driver/scss/main.min.125f72e5d5a3aa7d4039aab0c22c38a18b1796f8d41a399c1dbc59e50f290ecd.css as=style><link href=/azuredisk-csi-driver/scss/main.min.125f72e5d5a3aa7d4039aab0c22c38a18b1796f8d41a399c1dbc59e50f290ecd.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://unpkg.com/lunr@2.3.8/lunr.min.js integrity=sha384-vRQ9bDyE0Wnu+lMfm57BlYLO0/XauFuKpVsZPs7KEDwYKktWi5+Kz3MP8++DFlRY crossorigin=anonymous></script></head><body class=td-page><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/azuredisk-csi-driver/><span class=navbar-logo><svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="-.17 .08 230.1 223.35"><defs><style>.cls-1{fill:#fff}.cls-2{fill:#326ce5}</style></defs><path d="M134.358 126.466a3.59 3.59.0 00-.855-.065 3.685 3.685.0 00-1.425.37 3.725 3.725.0 00-1.803 4.825l-.026.037 8.528 20.603a43.53 43.53.0 0017.595-22.102l-21.976-3.714zm-34.194 2.92a3.72 3.72.0 00-3.568-2.894 3.656 3.656.0 00-.733.065-.037-.045-21.785 3.698a43.695 43.695.0 0017.54 21.946l8.442-20.4-.066-.08a3.683 3.683.0 00.207-2.29zm18.245 8a3.718 3.718.0 00-6.557.008h-.018l-10.713 19.372a43.637 43.637.0 0023.815 1.225q2.197-.5 4.292-1.2l-10.738-19.406zm33.914-45-16.483 14.753.009.047a3.725 3.725.0 001.46 6.395l.02.089 21.35 6.15a44.278 44.278.0 00-6.356-27.432zM121.7 94.039a3.725 3.725.0 005.913 2.84l.065.027 18.036-12.788a43.85 43.85.0 00-25.287-12.19l1.253 22.105zm-19.1 2.921a3.72 3.72.0 005.904-2.85l.092-.043 1.253-22.144a44.682 44.682.0 00-4.501.776 43.467 43.467.0 00-20.937 11.409 18.154 12.869zm-9.678 16.729a3.72 3.72.0 001.462-6.396l.018-.088-16.574-14.824a43.454 43.454.0 00-6.168 27.51l21.245-6.13zm16.098 6.512 6.114 2.94 6.096-2.934 1.514-6.581-4.219-5.276h-6.79l-4.231 5.268z" class="cls-2"/><path d="M216.208 133.167l-17.422-75.675a13.602 13.602.0 00-7.293-9.073l-70.521-33.67a13.589 13.589.0 00-11.705.0L38.76 48.437a13.598 13.598.0 00-7.295 9.072l-17.394 75.673a13.315 13.315.0 00-.004 5.81 13.506 13.506.0 00.491 1.718 13.1 13.1.0 001.343 2.726c.239.365.491.72.765 1.064l48.804 60.678c.213.264.448.505.681.75a13.423 13.423.0 002.574 2.133 13.924 13.924.0 003.857 1.677 13.298 13.298.0 003.43.473h.759l77.504-.018a12.993 12.993.0 001.41-.083 13.47 13.47.0 001.989-.378 13.872 13.872.0 001.381-.442c.353-.135.705-.27 1.045-.433a13.941 13.941.0 001.479-.822 13.303 13.303.0 003.237-2.865l1.488-1.85 47.299-58.84a13.185 13.185.0 002.108-3.785 13.67 13.67.0 00.5-1.724 13.282 13.282.0 00-.004-5.81zm-73.147 29.432a14.516 14.516.0 00.703 1.703 3.314 3.314.0 00-.327 2.49 39.372 39.372.0 003.742 6.7 35.06 35.06.0 012.263 3.364c.17.315.392.803.553 1.136a4.24 4.24.0 11-7.63 3.607c-.161-.33-.385-.77-.522-1.082a35.275 35.275.0 01-1.225-3.868 39.305 39.305.0 00-2.896-7.097 3.335 3.335.0 00-2.154-1.307-.135-.233-.635-1.15-.903-1.623a54.617 54.617.0 01-38.948-.1l-.955 1.733a3.429 3.429.0 00-1.819.887 29.517 29.517.0 00-3.268 7.582 34.9 34.9.0 01-1.218 3.868c-.135.31-.361.744-.522 1.073v.009l-.007.008a4.238 4.238.0 11-7.619-3.616c.159-.335.372-.82.54-1.135a35.177 35.177.0 012.262-3.373 41.228 41.228.0 003.82-6.866 4.188 4.188.0 00-.376-2.387l.768-1.84a54.922 54.922.0 01-24.338-30.387l-1.839.313a4.68 4.68.0 00-2.428-.855 39.524 39.524.0 00-7.356 2.165 35.589 35.589.0 01-3.787 1.45c-.305.084-.745.168-1.093.244-.028.01-.052.022-.08.029a.605.605.0 01-.065.006 4.236 4.236.0 11-1.874-8.224l.061-.015.037-.01c.353-.083.805-.2 1.127-.262a35.27 35.27.0 014.05-.326 39.388 39.388.0 007.564-1.242 5.835 5.835.0 001.814-1.83l1.767-.516a54.613 54.613.0 018.613-38.073l-1.353-1.206a4.688 4.688.0 00-.848-2.436 39.366 39.366.0 00-6.277-4.41 35.25 35.25.0 01-3.499-2.046c-.256-.191-.596-.478-.874-.704l-.063-.044a4.473 4.473.0 01-1.038-6.222 4.066 4.066.0 013.363-1.488 5.03 5.03.0 012.942 1.11c.287.225.68.526.935.745a35.253 35.253.0 012.78 2.95 39.383 39.383.0 005.69 5.142 3.333 3.333.0 002.507.243q.754.55 1.522 1.082A54.289 54.289.0 01102.86 61.89a55.052 55.052.0 017.63-1.173l.1-1.784a4.6 4.6.0 001.37-2.184 39.476 39.476.0 00-.47-7.654 35.466 35.466.0 01-.576-4.014c-.011-.307.006-.731.01-1.081.0-.04-.01-.08-.01-.118a4.242 4.242.0 118.441-.004c0 .37.022.86.009 1.2a35.109 35.109.0 01-.579 4.013 39.533 39.533.0 00-.478 7.656 3.344 3.344.0 001.379 2.11.015.305.065 1.323.102 1.884a55.309 55.309.0 0135.032 16.927l1.606-1.1477a4.69 4.69.0 002.56-.278 39.532 39.532.0 005.69-5.148 35.004 35.004.0 012.787-2.95c.259-.222.65-.52.936-.746a4.242 4.242.0 115.258 6.598c-.283.229-.657.548-.929.75a35.095 35.095.0 01-3.507 2.046 39.495 39.495.0 00-6.277 4.41 3.337 3.337.0 00-.792 2.39-.235.216-1.06.947-1.497 1.343a54.837 54.837.0 018.792 37.983l1.704.4966a4.745 4.745.0 001.82 1.83 39.464 39.464.0 007.568 1.246 35.64 35.64.0 014.046.324c.355.065.868.207 1.23.29a4.236 4.236.0 11-1.878 8.223l-.061-.008c-.028-.007-.054-.022-.083-.03-.348-.075-.785-.151-1.09-.231a35.14 35.14.0 01-3.785-1.462 39.477 39.477.0 00-7.363-2.165 3.337 3.337.0 00-2.362.877q-.9-.171-1.804-.316a54.92 54.92.0 01-24.328 30.605z" class="cls-2"/><path d="M225.407 135.107 206.4 52.547a14.838 14.838.0 00-7.958-9.9l-76.935-36.73a14.825 14.825.0 00-12.771.0L31.808 42.669a14.838 14.838.0 00-7.961 9.895L4.873 135.129a14.668 14.668.0 001.995 11.185c.261.4.538.788.838 1.162l53.246 66.205a14.98 14.98.0 0011.499 5.487l85.387-.02a14.986 14.986.0 0011.5-5.48l53.227-66.211a14.72 14.72.0 002.842-12.347zm-9.197 3.866a13.677 13.677.0 01-.498 1.723 13.184 13.184.0 01-2.11 3.786-47.299 58.838-1.486 1.8522a13.305 13.305.0 01-3.24 2.865 13.945 13.945.0 01-1.474.822q-.513.237-1.045.43a13.873 13.873.0 01-1.383.445 13.473 13.473.0 01-1.989.379 12.988 12.988.0 01-1.41.082l-77.504.018h-.76a13.298 13.298.0 01-3.429-.472 13.925 13.925.0 01-3.855-1.679 13.424 13.424.0 01-2.576-2.132c-.233-.246-.468-.487-.68-.75l-48.805-60.679q-.408-.514-.765-1.066a13.102 13.102.0 01-1.343-2.726 13.505 13.505.0 01-.491-1.719 13.315 13.315.0 01.004-5.809l17.394-75.675a13.598 13.598.0 017.295-9.07l70.508-33.685a13.589 13.589.0 0111.705.0l70.519 33.67a13.602 13.602.0 017.293 9.073l17.422 75.674a13.282 13.282.0 01.002 5.807z" class="cls-1"/><path d="M185.814 127.106c-.36-.083-.874-.225-1.227-.29a35.642 35.642.0 00-4.046-.326 39.464 39.464.0 01-7.57-1.242 4.745 4.745.0 01-1.82-1.832l-1.704-.496a54.837 54.837.0 00-8.79-37.983c.436-.396 1.262-1.127 1.495-1.342a3.338 3.338.0 01.792-2.39 39.495 39.495.0 016.277-4.41 35.095 35.095.0 003.507-2.046.272-.202.644-.522.929-.75a4.242 4.242.0 10-5.256-6.6c-.288.227-.68.525-.936.7477a35.004 35.004.0 00-2.789 2.95 39.533 39.533.0 01-5.69 5.148 4.69 4.69.0 01-2.56.278l-1.606 1.147a55.309 55.309.0 00-35.032-16.927c-.039-.561-.087-1.577-.102-1.884a3.344 3.344.0 01-1.377-2.11 39.533 39.533.0 01.478-7.656 35.112 35.112.0 00.575-4.012.013-.34-.007-.834-.007-1.201a4.242 4.242.0 10-8.441.004c0 .04.009.078.01.118-.004.35-.021.774-.01 1.088a35.476 35.476.0 00.576 4.015 39.475 39.475.0 01.47 7.654 4.601 4.601.0 01-1.37 2.182l-.1 1.786a55.052 55.052.0 00-7.63 1.173 54.289 54.289.0 00-27.574 15.754q-.77-.531-1.526-1.082a3.333 3.333.0 01-2.506-.243 39.383 39.383.0 01-5.69-5.141 35.255 35.255.0 00-2.777-2.95c-.257-.22-.65-.52-.938-.75a5.03 5.03.0 00-2.942-1.11 4.066 4.066.0 00-3.363 1.49 4.473 4.473.0 001.038 6.222l.065.046c.276.226.616.515.872.702a35.256 35.256.0 003.499 2.048 39.367 39.367.0 016.276 4.412 4.69 4.69.0 01.849 2.434l1.351 1.208a54.613 54.613.0 00-8.611 38.073l-1.767.514a5.835 5.835.0 01-1.814 1.827 39.39 39.39.0 01-7.565 1.247 35.266 35.266.0 00-4.049.326c-.324.06-.774.174-1.127.262l-.037.008-.06.018a4.236 4.236.0 101.875 8.224l.063-.01c.028-.006.052-.02.08-.025.348-.08.786-.163 1.092-.246a35.59 35.59.0 003.786-1.451 39.527 39.527.0 017.358-2.165 4.68 4.68.0 012.426.857l1.84-.315a54.922 54.922.0 0024.34 30.387l-.769 1.84a4.188 4.188.0 01.377 2.387 41.228 41.228.0 01-3.82 6.864 35.183 35.183.0 00-2.263 3.372c-.168.318-.381.805-.542 1.138a4.238 4.238.0 107.621 3.616l.007-.008v-.01c.16-.33.387-.763.522-1.072a34.903 34.903.0 001.218-3.868 29.517 29.517.0 013.268-7.582 3.43 3.43.0 011.819-.888l.957-1.73a54.617 54.617.0 0038.946.099c.268.478.768 1.392.9 1.623a3.335 3.335.0 012.155 1.31 39.306 39.306.0 012.898 7.096 35.275 35.275.0 001.225 3.868.137.312.36.75.522 1.082a4.24 4.24.0 107.63-3.607c-.161-.333-.383-.82-.55-1.1366a35.06 35.06.0 00-2.263-3.364 39.372 39.372.0 01-3.742-6.7 3.314 3.314.0 01.324-2.49 14.519 14.519.0 01-.703-1.703 54.92 54.92.0 0024.328-30.605.546.087 1.497.253 1.806.3166a3.337 3.337.0 012.36-.877 39.476 39.476.0 017.36 2.165 35.135 35.135.0 003.788 1.462.305.08.74.156 1.09.233.029.008.055.02.083.028l.06.009a4.236 4.236.0 101.878-8.224zm-40.1-42.987-18.037 12.787-.063-.03a3.723 3.723.0 01-5.913-2.838l-.02-.01-1.253-22.103a43.85 43.85.0 0125.285 12.194zm-33.978 24.228h6.788l4.22 5.276-1.513 6.58-6.096 2.934-6.114-2.94-1.516-6.583zm-6.386-35.648a44.672 44.672.0 014.503-.774l-1.255 22.137-.092.044a3.72 3.72.0 01-5.904 2.852l-.035.02-18.154-12.872a43.467 43.467.0 0120.937-11.407zm-27.52 19.68 16.574 14.824-.018.09a3.72 3.72.0 01-1.462 6.395l-.017.072-21.245 6.13a43.454 43.454.0 016.168-27.51zm22.191 39.38-8.441 20.397a43.696 43.696.0 01-17.536-21.948l21.783-3.7.037.0499a3.655 3.655.0 01.73-.065 3.72 3.72.0 013.364 5.185zm24.916 26.23a43.637 43.637.0 01-23.815-1.223l10.713-19.372h.018a3.725 3.725.0 016.557-.006h.08l10.74 19.404q-2.091.698-4.293 1.199zm13.841-5.751-8.528-20.605.026-.037a3.725 3.725.0 011.803-4.823 3.685 3.685.0 011.425-.37 3.59 3.59.0 01.855.063.037-.046 21.977 3.714a43.53 43.53.0 01-17.595 22.105zm19.903-32.42-21.352-6.15-.02-.09a3.725 3.725.0 01-1.46-6.395l-.008-.043 16.482-14.751a44.279 44.279.0 016.357 27.43z" class="cls-1"/></svg></span><span class="text-uppercase font-weight-bold">AzureDisk CSI Driver</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/azuredisk-csi-driver/install/><span>Installation</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/azuredisk-csi-driver/development/><span>Development</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/azuredisk-csi-driver/features/><span>Features</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/azuredisk-csi-driver/contribute/><span>Contribution</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/azuredisk-csi-driver/example/><span>Example</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/azuredisk-csi-driver/blog/><span>Release Notes</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/azuredisk-csi-driver/faq/><span class=active>FAQ</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/azuredisk-csi-driver/offline-search-index.bf93bb6b2d7a00dc36522bfd4bfbb7ccfb316b34e618e27fd7ce94592435654dd6ef35bf734cf74cdf9d2a274e46c33d858eace802c0b49de82a7efe8f68d9c1.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/azuredisk-csi-driver/offline-search-index.bf93bb6b2d7a00dc36522bfd4bfbb7ccfb316b34e618e27fd7ce94592435654dd6ef35bf734cf74cdf9d2a274e46c33d858eace802c0b49de82a7efe8f68d9c1.json data-offline-search-base-href=/ data-offline-search-max-results=10>
<button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type=button data-toggle=collapse data-target=#td-section-nav aria-controls=td-docs-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="collapse td-sidebar-nav" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/azuredisk-csi-driver/faq/ class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">FAQ</a></li><ul><li class="collapse show" id=azuredisk-csi-driver-faq><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/azuredisk-csi-driver/faq/known-issues/ class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">Known Issues</a></li><ul><li class="collapse show" id=azuredisk-csi-driver-faq-known-issues><a class="td-sidebar-link td-sidebar-link__page active" id=m-azuredisk-csi-driver-faq-known-issues-azuredisk href=/azuredisk-csi-driver/faq/known-issues/azuredisk/>AzureDisk</a></li></ul></ul></li></ul></ul></nav></div></div><div class="d-none d-xl-block col-xl-2 td-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"><a href=https://github.com/kubernetes-sigs/azuredisk-csi-driver/edit/master/content/en/FAQ/known-issues/azuredisk.md target=_blank><i class="fa fa-edit fa-fw"></i>Edit this page</a>
<a href="https://github.com/kubernetes-sigs/azuredisk-csi-driver/issues/new?title=AzureDisk%20CSI%20Driver%20Known%20Issues" target=_blank><i class="fab fa-github fa-fw"></i>Create documentation issue</a>
<a href=https://github.com/kubernetes-sigs/azuredisk-csi-driver/issues/new target=_blank><i class="fas fa-tasks fa-fw"></i>Create project issue</a></div><nav id=TableOfContents><ul><li><a href=#recommended-stable-version-for-azure-disk>Recommended stable version for azure disk</a></li><li><a href=#1-disk-attach-error>1. disk attach error</a></li><li><a href=#2-disk-unavailable-after-attachdetach-a-data-disk-on-a-node>2. disk unavailable after attach/detach a data disk on a node</a></li><li><a href=#3-azure-disk-support-on-sovereign-cloud>3. Azure disk support on Sovereign Cloud</a></li><li><a href=#4-time-cost-for-azure-disk-pvc-mount>4. Time cost for Azure Disk PVC mount</a></li><li><a href=#5-azure-disk-pvc-multi-attach-error-makes-disk-mount-very-slow-or-mount-failure-forever>5. Azure disk PVC Multi-Attach error, makes disk mount very slow or mount failure forever</a></li><li><a href=#6-waitforattach-failed-for-azure-disk-parsing-devdiskazurescsi1lun1-invalid-syntax>6. WaitForAttach failed for azure disk: parsing &ldquo;/dev/disk/azure/scsi1/lun1&rdquo;: invalid syntax</a></li><li><a href=#7-uid-and-gid-setting-in-azure-disk>7. uid and gid setting in azure disk</a></li><li><a href=#8-addition-of-a-blob-based-disk-to-vm-with-managed-disks-is-not-supported>8. Addition of a blob based disk to VM with managed disks is not supported</a></li><li><a href=#9-dynamic-azure-disk-pvc-try-to-access-wrong-storage-account-of-other-resource-group>9. dynamic azure disk PVC try to access wrong storage account (of other resource group)</a></li><li><a href=#10-data-loss-if-using-existing-azure-disk-with-partitions-in-disk-mount>10. data loss if using existing azure disk with partitions in disk mount</a></li><li><a href=#11-delete-azure-disk-pvc-which-is-already-in-use-by-a-pod>11. Delete azure disk PVC which is already in use by a pod</a></li><li><a href=#12-create-azure-disk-pvc-failed-due-to-account-creation-failure>12. create azure disk PVC failed due to account creation failure</a></li><li><a href=#13-cannot-find-lun-for-disk>13. cannot find Lun for disk</a></li><li><a href=#14-azure-disk-attachdetach-failure-mount-issue-io-error>14. azure disk attach/detach failure, mount issue, i/o error</a></li></ul></nav></div><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><nav aria-label=breadcrumb class="d-none d-md-block d-print-none"><ol class="breadcrumb spb-1"><li class=breadcrumb-item><a href=https://Sakuralbj.github.io/azuredisk-csi-driver/faq/>FAQ</a></li><li class=breadcrumb-item><a href=https://Sakuralbj.github.io/azuredisk-csi-driver/faq/known-issues/>Known Issues</a></li><li class="breadcrumb-item active" aria-current=page><a href=https://Sakuralbj.github.io/azuredisk-csi-driver/faq/known-issues/azuredisk/>AzureDisk</a></li></ol></nav><div class=td-content><h1>AzureDisk CSI Driver Known Issues</h1><ul><li><a href=#azure-disk-plugin-known-issues>azure disk plugin known issues</a><ul><li><a href=#recommended-stable-version-for-azure-disk>Recommended stable version for azure disk</a></li><li><a href=#1-disk-attach-error>1. disk attach error</a></li><li><a href=#2-disk-unavailable-after-attachdetach-a-data-disk-on-a-node>2. disk unavailable after attach/detach a data disk on a node</a></li><li><a href=#3-azure-disk-support-on-sovereign-cloud>3. Azure disk support on Sovereign Cloud</a></li><li><a href=#4-time-cost-for-azure-disk-pvc-mount>4. Time cost for Azure Disk PVC mount</a></li><li><a href=#5-azure-disk-pvc-multi-attach-error-makes-disk-mount-very-slow-or-mount-failure-forever>5. Azure disk PVC <code>Multi-Attach error</code>, makes disk mount very slow or mount failure forever</a></li><li><a href=#6-waitforattach-failed-for-azure-disk-parsing-devdiskazurescsi1lun1-invalid-syntax>6. WaitForAttach failed for azure disk: parsing &ldquo;/dev/disk/azure/scsi1/lun1&rdquo;: invalid syntax</a></li><li><a href=#7-uid-and-gid-setting-in-azure-disk>7. <code>uid</code> and <code>gid</code> setting in azure disk</a></li><li><a href=#8-addition-of-a-blob-based-disk-to-vm-with-managed-disks-is-not-supported>8. <code>Addition of a blob based disk to VM with managed disks is not supported</code></a></li><li><a href=#9-dynamic-azure-disk-pvc-try-to-access-wrong-storage-account-of-other-resource-group>9. dynamic azure disk PVC try to access wrong storage account (of other resource group)</a></li><li><a href=#10-data-loss-if-using-existing-azure-disk-with-partitions-in-disk-mount>10. data loss if using existing azure disk with partitions in disk mount</a></li><li><a href=#11-delete-azure-disk-pvc-which-is-already-in-use-by-a-pod>11. Delete azure disk PVC which is already in use by a pod</a></li><li><a href=#12-create-azure-disk-pvc-failed-due-to-account-creation-failure>12. create azure disk PVC failed due to account creation failure</a></li><li><a href=#13-cannot-find-Lun-for-disk>13. cannot find Lun for disk</a></li><li><a href=#14-azure-disk-attachdetach-failure-mount-issue-io-error>14. azure disk attach/detach failure, mount issue, i/o error</a></li></ul></li></ul><h2 id=recommended-stable-version-for-azure-disk>Recommended stable version for azure disk</h2><table><thead><tr><th>k8s version</th><th>stable version</th></tr></thead><tbody><tr><td>v1.7</td><td>1.7.14 or later</td></tr><tr><td>v1.8</td><td>1.8.13 or later</td></tr><tr><td>v1.9</td><td>1.9.7 or later (1.9.6 on AKS)</td></tr><tr><td>v1.10</td><td>1.10.12 or later</td></tr><tr><td>v1.11</td><td>1.11.6 or later</td></tr><tr><td>v1.12</td><td>1.12.4 or later</td></tr><tr><td>v1.13</td><td>1.13.0</td></tr></tbody></table><h2 id=1-disk-attach-error>1. disk attach error</h2><p><strong>Issue details</strong>:</p><p>In some corner case(detaching multiple disks on a node simultaneously), when scheduling a pod with azure disk mount from one node to another, there could be lots of disk attach error(no recovery) due to the disk not being released in time from the previous node. This issue is due to lack of lock before DetachDisk operation, actually there should be a central lock for both AttachDisk and DetachDisk operations, only one AttachDisk or DetachDisk operation is allowed at one time.</p><p>The disk attach error could be like following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>Cannot attach data disk <span style=color:#4e9a06>&#39;cdb-dynamic-pvc-92972088-11b9-11e8-888f-000d3a018174&#39;</span> to VM <span style=color:#4e9a06>&#39;kn-edge-0&#39;</span> because the disk is currently being detached or the last detach operation failed. Please <span style=color:#204a87>wait</span> <span style=color:#204a87;font-weight:700>until</span> the disk is completely detached and <span style=color:#204a87;font-weight:700>then</span> try again or delete/detach the disk explicitly again.
</code></pre></div><p><strong>Related issues</strong></p><ul><li><a href=https://github.com/kubernetes/kubernetes/issues/60101>Azure Disk Detach are not working with multiple disk detach on the same Node</a></li><li><a href=https://github.com/kubernetes/kubernetes/issues/46421>Azure disk fails to attach and mount, causing rescheduled pod to stall following node disruption</a></li><li><a href=https://github.com/Azure/acs-engine/issues/2002>Since Intel CPU Azure update, new Azure Disks are not mounting, very critical&mldr;</a></li><li><a href=https://github.com/Azure/ACS/issues/12>Busy azure-disk regularly fail to mount causing K8S Pod deployments to halt</a></li></ul><p><strong>Mitigation</strong>:</p><ul><li>option#1: Update every agent node that has attached or detached the disk in problem</li></ul><p>In Azure cloud shell, run</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#000>$vm</span> <span style=color:#ce5c00;font-weight:700>=</span> Get-AzureRMVM -ResourceGroupName <span style=color:#000>$rg</span> -Name <span style=color:#000>$vmname</span>
Update-AzureRmVM -ResourceGroupName <span style=color:#000>$rg</span> -VM <span style=color:#000>$vm</span> -verbose -debug
</code></pre></div><p>In Azure cli, run</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>az vm update -g &lt;group&gt; -n &lt;name&gt;
</code></pre></div><ul><li>option#2:</li></ul><ol><li><code>kubectl cordon node</code> #make sure no scheduling on this node</li><li><code>kubectl drain node</code> #schedule pod in current node to other node</li><li>restart the Azure VM for node via the API or portal, wait until VM is &ldquo;Running&rdquo;</li><li><code>kubectl uncordon node</code></li></ol><p><strong>Fix</strong></p><ul><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/60183>fix race condition issue when detaching azure disk</a> has fixed this issue by add a lock before DetachDisk</li></ul><table><thead><tr><th>k8s version</th><th>fixed version</th></tr></thead><tbody><tr><td>v1.6</td><td>no fix since v1.6 does not accept any cherry-pick</td></tr><tr><td>v1.7</td><td>1.7.14</td></tr><tr><td>v1.8</td><td>1.8.9</td></tr><tr><td>v1.9</td><td>1.9.5</td></tr><tr><td>v1.10</td><td>1.10.0</td></tr></tbody></table><h2 id=2-disk-unavailable-after-attachdetach-a-data-disk-on-a-node>2. disk unavailable after attach/detach a data disk on a node</h2><blockquote><p>💡 NOTE: Azure platform has fixed the host cache issue, the suggested host cache setting of data disk is <code>ReadOnly</code> now, more details about <a href=https://docs.microsoft.com/en-us/azure/virtual-machines/windows/premium-storage-performance#disk-caching>azure disk cache setting</a>
<strong>Issue details</strong>:</p></blockquote><p>From k8s v1.7, default host cache setting changed from <code>None</code> to <code>ReadWrite</code>, this change would lead to device name change after attach multiple disks on a node, finally lead to disk unavailable from pod. When access data disk inside a pod, will get following error:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#ce5c00;font-weight:700>[</span>root@admin-0 /<span style=color:#ce5c00;font-weight:700>]</span><span style=color:#8f5902;font-style:italic># ls /datadisk</span>
ls: reading directory .: Input/output error
</code></pre></div><p>In my testing on Ubuntu 16.04 D2_V2 VM, when attaching the 6th data disk will cause device name change on agent node, e.g. following lun0 disk should be <code>sdc</code> other than <code>sdk</code>.</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>azureuser@k8s-agentpool2-40588258-0:~$ tree /dev/disk/azure
...
â””â”€â”€ scsi1
    â”œâ”€â”€ lun0 -&gt; ../../../sdk
    â”œâ”€â”€ lun1 -&gt; ../../../sdj
    â”œâ”€â”€ lun2 -&gt; ../../../sde
    â”œâ”€â”€ lun3 -&gt; ../../../sdf
    â”œâ”€â”€ lun4 -&gt; ../../../sdg
    â”œâ”€â”€ lun5 -&gt; ../../../sdh
    â””â”€â”€ lun6 -&gt; ../../../sdi
</code></pre></div><p><strong>Related issues</strong></p><ul><li><a href=https://github.com/kubernetes/kubernetes/issues/60344>device name change due to azure disk host cache setting</a></li><li><a href=https://github.com/kubernetes/kubernetes/issues/57444>unable to use azure disk in StatefulSet since /dev/sd* changed after detach/attach disk</a></li><li><a href=https://github.com/Azure/AKS/issues/201>Disk error when pods are mounting a certain amount of volumes on a node</a></li><li><a href=https://github.com/Azure/acs-engine/issues/1918>unable to use azure disk in StatefulSet since /dev/sd* changed after detach/attach disk</a></li><li><a href=https://github.com/Azure/AKS/issues/297>Input/output error when accessing PV</a></li><li><a href=https://github.com/Azure/ACS/issues/113>PersistentVolumeClaims changing to Read-only file system suddenly</a></li></ul><p><strong>Workaround</strong>:</p><ul><li>add <code>cachingmode: None</code> in azure disk storage class(default is <code>ReadWrite</code>), e.g.</li></ul><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>kind<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>StorageClass<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span>apiVersion<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>storage.k8s.io/v1<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span>metadata<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span>name<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>hdd<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span>provisioner<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>kubernetes.io/azure-disk<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span>parameters<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span>skuname<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>Standard_LRS<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span>kind<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>Managed<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span>cachingmode<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>None<span style=color:#f8f8f8;text-decoration:underline>
</span></code></pre></div><p><strong>Fix</strong></p><ul><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/60346>fix device name change issue for azure disk</a> could fix this issue too, it will change default <code>cachingmode</code> value from <code>ReadWrite</code> to <code>None</code>.</li></ul><table><thead><tr><th>k8s version</th><th>fixed version</th></tr></thead><tbody><tr><td>v1.6</td><td>no such issue as <code>cachingmode</code> is already <code>None</code> by default</td></tr><tr><td>v1.7</td><td>1.7.14</td></tr><tr><td>v1.8</td><td>1.8.11</td></tr><tr><td>v1.9</td><td>1.9.4</td></tr><tr><td>v1.10</td><td>1.10.0</td></tr></tbody></table><h2 id=3-azure-disk-support-on-sovereign-cloud>3. Azure disk support on Sovereign Cloud</h2><p><strong>Fix</strong></p><ul><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/50673>Azure disk on Sovereign Cloud</a> fixed this issue</li></ul><table><thead><tr><th>k8s version</th><th>fixed version</th></tr></thead><tbody><tr><td>v1.7</td><td>1.7.9</td></tr><tr><td>v1.8</td><td>1.8.3</td></tr><tr><td>v1.9</td><td>1.9.0</td></tr><tr><td>v1.10</td><td>1.10.0</td></tr></tbody></table><h2 id=4-time-cost-for-azure-disk-pvc-mount>4. Time cost for Azure Disk PVC mount</h2><p>Original time cost for Azure Disk PVC mount on a standard node size(e.g. Standard_D2_V2) is around 1 minute, <code>podAttachAndMountTimeout</code> is <a href=https://github.com/kubernetes/kubernetes/blob/release-1.7/pkg/kubelet/volumemanager/volume_manager.go#L76>2 minutes</a>, total <code>waitForAttachTimeout</code> is <a href=https://github.com/kubernetes/kubernetes/blob/release-1.7/pkg/kubelet/volumemanager/volume_manager.go#L88>10 minutes</a>, so a disk remount(detach and attach in sequential) would possibly cost more than 2min, thus may fail.</p><blockquote><p>Note: for some smaller VM size which has only 1 CPU core, time cost would be much bigger(e.g. > 10min) since container is hard to get CPU slot.</p></blockquote><p><strong>Related issues</strong></p><ul><li><a href=https://github.com/Azure/AKS/issues/166>&lsquo;timeout expired waiting for volumes to attach/mount for pod when cluster&rsquo; when node-vm-size is Standard_B1s</a></li></ul><p><strong>Fix</strong></p><ul><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/57432>using cache fix</a> fixed this issue, which could reduce the mount time cost to around 30s.</li></ul><table><thead><tr><th>k8s version</th><th>fixed version</th></tr></thead><tbody><tr><td>v1.8</td><td>no fix</td></tr><tr><td>v1.9</td><td>1.9.2</td></tr><tr><td>v1.10</td><td>1.10.0</td></tr></tbody></table><h2 id=5-azure-disk-pvc-multi-attach-error-makes-disk-mount-very-slow-or-mount-failure-forever>5. Azure disk PVC <code>Multi-Attach error</code>, makes disk mount very slow or mount failure forever</h2><p><strong>Issue details</strong>:</p><p>When schedule a pod with azure disk volume from one node to another, total time cost of detach & attach is around 1 min from v1.9.2, while in v1.9.x, there is an <a href=https://github.com/kubernetes/kubernetes/issues/62282>UnmountDevice failure issue in containerized kubelet</a> which makes disk mount very slow or mount failure forever, this issue only exists in v1.9.x due to PR <a href=https://github.com/kubernetes/kubernetes/pull/51771>Refactor nsenter</a>, v1.10.0 won't have this issue since <code>devicePath</code> is updated in <a href=https://github.com/kubernetes/kubernetes/blob/release-1.10/pkg/volume/util/operationexecutor/operation_generator.go#L1130-L1131>v1.10 code</a></p><p><strong>error logs</strong>:</p><ul><li><code>kubectl describe po POD-NAME</code></li></ul><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>Events:
  Type     Reason                 Age   From                               Message
  ----     ------                 ----  ----                               -------
  Normal   Scheduled              3m    default-scheduler                  Successfully assigned deployment-azuredisk1-6cd8bc7945-kbkvz to k8s-agentpool-88970029-0
  Warning  FailedAttachVolume     3m    attachdetach-controller            Multi-Attach error <span style=color:#204a87;font-weight:700>for</span> volume <span style=color:#4e9a06>&#34;pvc-6f2d0788-3b0b-11e8-a378-000d3afe2762&#34;</span> Volume is already exclusively attached to one node and can<span style=color:#a40000>&#39;</span>t be attached to another
  Normal   SuccessfulMountVolume  3m    kubelet, k8s-agentpool-88970029-0  MountVolume.SetUp succeeded <span style=color:#204a87;font-weight:700>for</span> volume <span style=color:#4e9a06>&#34;default-token-qt7h6&#34;</span>
  Warning  FailedMount            1m    kubelet, k8s-agentpool-88970029-0  Unable to mount volumes <span style=color:#204a87;font-weight:700>for</span> pod <span style=color:#4e9a06>&#34;deployment-azuredisk1-6cd8bc7945-kbkvz_default(5346c040-3e4c-11e8-a378-000d3afe2762)&#34;</span>: timeout expired waiting <span style=color:#204a87;font-weight:700>for</span> volumes to attach/mount <span style=color:#204a87;font-weight:700>for</span> pod <span style=color:#4e9a06>&#34;default&#34;</span>/<span style=color:#4e9a06>&#34;deployment-azuredisk1-6cd8bc7945-kbkvz&#34;</span>. list of unattached/unmounted <span style=color:#000>volumes</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#ce5c00;font-weight:700>[</span>azuredisk<span style=color:#ce5c00;font-weight:700>]</span>
</code></pre></div><ul><li>kubelet logs from the new node</li></ul><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>E0412 20:08:10.920284    <span style=color:#0000cf;font-weight:700>7602</span> nestedpendingoperations.go:263<span style=color:#ce5c00;font-weight:700>]</span> Operation <span style=color:#204a87;font-weight:700>for</span> <span style=color:#4e9a06>&#34;\&#34;kubernetes.io/azure-disk//subscriptions/xxx/resourceGroups/MC_xxx_eastus/providers/Microsoft.Compute/disks/kubernetes-dynamic-pvc-11035a31-3e8d-11e8-82ec-0a58ac1f04cf\&#34;&#34;</span> failed. No retries permitted <span style=color:#204a87;font-weight:700>until</span> 2018-04-12 20:08:12.920234762 +0000 UTC <span style=color:#000>m</span><span style=color:#ce5c00;font-weight:700>=</span>+1467.278612421 <span style=color:#ce5c00;font-weight:700>(</span>durationBeforeRetry 2s<span style=color:#ce5c00;font-weight:700>)</span>. Error: <span style=color:#4e9a06>&#34;Volume has not been added to the list of VolumesInUse in the node&#39;s volume status for volume \&#34;pvc-11035a31-3e8d-11e8-82ec-0a58ac1f04cf\&#34; (UniqueName: \&#34;kubernetes.io/azure-disk//subscriptions/xxx/resourceGroups/MC_xxx_eastus/providers/Microsoft.Compute/disks/kubernetes-dynamic-pvc-11035a31-3e8d-11e8-82ec-0a58ac1f04cf\&#34;) pod \&#34;symbiont-node-consul-0\&#34; (UID: \&#34;11043b12-3e8d-11e8-82ec-0a58ac1f04cf\&#34;) &#34;</span>
</code></pre></div><p><strong>Related issues</strong></p><ul><li><a href=https://github.com/kubernetes/kubernetes/issues/62282>UnmountDevice would fail in containerized kubelet</a></li><li><a href=https://github.com/Azure/acs-engine/issues/2022>upgrade k8s process is broke</a></li></ul><p><strong>Mitigation</strong>:</p><p>If azure disk PVC mount successfully in the end, there is no action, while if it could not be mounted for more than 20min, following actions could be taken:</p><ul><li>check whether <code>volumesInUse</code> list has unmounted azure disks, run:</li></ul><pre><code>kubectl get no NODE-NAME -o yaml &gt; node.log
</code></pre><p>all volumes in <code>volumesInUse</code> should be also in <code>volumesAttached</code>, otherwise there would be issue</p><ul><li>restart kubelet on the original node would solve this issue: <code>sudo kubectl kubelet restart</code></li></ul><p><strong>Fix</strong></p><ul><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/62467>fix nsenter GetFileType issue in containerized kubelet</a> fixed this issue</li></ul><table><thead><tr><th>k8s version</th><th>fixed version</th></tr></thead><tbody><tr><td>v1.8</td><td>no such issue</td></tr><tr><td>v1.9</td><td>v1.9.7</td></tr><tr><td>v1.10</td><td>no such issue</td></tr></tbody></table><p>After fix in v1.9.7, it took about 1 minute for scheduling one azure disk mount from one node to another, you could find details <a href=https://github.com/kubernetes/kubernetes/issues/62282#issuecomment-380794459>here</a>.</p><p>Since azure disk attach/detach operation on a VM cannot be parallel, scheduling 3 azure disk mounts from one node to another would cost about 3 minutes.</p><h2 id=6-waitforattach-failed-for-azure-disk-parsing-devdiskazurescsi1lun1-invalid-syntax>6. WaitForAttach failed for azure disk: parsing &ldquo;/dev/disk/azure/scsi1/lun1&rdquo;: invalid syntax</h2><p><strong>Issue details</strong>:
MountVolume.WaitForAttach may fail in the azure disk remount</p><p><strong>error logs</strong>:</p><p>in v1.10.0 & v1.10.1, <code>MountVolume.WaitForAttach</code> will fail in the azure disk remount, error logs would be like following:</p><ul><li>incorrect <code>DevicePath</code> format on Linux</li></ul><pre><code>MountVolume.WaitForAttach failed for volume &quot;pvc-f1562ecb-3e5f-11e8-ab6b-000d3af9f967&quot; : azureDisk - Wait for attach expect device path as a lun number, instead got: /dev/disk/azure/scsi1/lun1 (strconv.Atoi: parsing &quot;/dev/disk/azure/scsi1/lun1&quot;: invalid syntax)
  Warning  FailedMount             1m (x10 over 21m)   kubelet, k8s-agentpool-66825246-0  Unable to mount volumes for pod
</code></pre><ul><li>wrong <code>DevicePath</code>(LUN) number on Windows</li></ul><pre><code>  Warning  FailedMount             1m    kubelet, 15282k8s9010    MountVolume.WaitForAttach failed for volume &quot;disk01&quot; : azureDisk - WaitForAttach failed within timeout node (15282k8s9010) diskId:(andy-mghyb
1102-dynamic-pvc-6c526c51-4a18-11e8-ab5c-000d3af7b38e) lun:(4)
</code></pre><p><strong>Related issues</strong></p><ul><li><a href=https://github.com/kubernetes/kubernetes/issues/62540>WaitForAttach failed for azure disk: parsing &ldquo;/dev/disk/azure/scsi1/lun1&rdquo;: invalid syntax</a></li><li><a href=https://github.com/Azure/acs-engine/issues/2906>Pod unable to attach PV after being deleted (Wait for attach expect device path as a lun number, instead got: /dev/disk/azure/scsi1/lun0 (strconv.Atoi: parsing &ldquo;/dev/disk/azure/scsi1/lun0&rdquo;: invalid syntax)</a></li></ul><p><strong>Fix</strong></p><ul><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/62612>fix WaitForAttach failure issue for azure disk</a> fixed this issue</li></ul><table><thead><tr><th>k8s version</th><th>fixed version</th></tr></thead><tbody><tr><td>v1.8</td><td>no such issue</td></tr><tr><td>v1.9</td><td>no such issue</td></tr><tr><td>v1.10</td><td>1.10.2</td></tr></tbody></table><h2 id=7-uid-and-gid-setting-in-azure-disk>7. <code>uid</code> and <code>gid</code> setting in azure disk</h2><p><strong>Issue details</strong>:
Unlike azure file mountOptions, you will get following failure if set <code>mountOptions</code> like <code>uid=999,gid=999</code> in azure disk mount:</p><pre><code>azureDisk - mountDevice:FormatAndMount failed with exit status 32
</code></pre><p>That's because azureDisk use ext4 file system by default, mountOptions like [uid=x,gid=x] could not be set in mount time.</p><p><strong>Related issues</strong></p><ul><li><a href=https://github.com/kubernetes/kubernetes/issues/67014>Timeout expired waiting for volumes to attach</a></li></ul><p><strong>Solution</strong>:</p><ul><li>option#1: Set uid in <code>runAsUser</code> and gid in <code>fsGroup</code> for pod: <a href=https://kubernetes.io/docs/tasks/configure-pod-container/security-context/>security context for a Pod</a></li></ul><p>e.g. Following setting will set pod run as root, make it accessible to any file:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>v1<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span>kind<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>Pod<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span>metadata<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span>name<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>security-context-demo<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span>spec<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span>securityContext<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span>runAsUser<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>0</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span>fsGroup<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>0</span><span style=color:#f8f8f8;text-decoration:underline>
</span></code></pre></div><blockquote><p>Note: Since gid & uid is mounted as 0(root) by default, if set as non-root(e.g. 1000), k8s will use chown to change all dir/files under that disk, this is a time consuming job, which would make mount device very slow, in this issue: <a href=https://github.com/kubernetes/kubernetes/issues/67014#issuecomment-413546283>Timeout expired waiting for volumes to attach</a>, it costs about 10 min for chown operation complete.</p></blockquote><ul><li>option#2: use <code>chown</code> in <code>initContainers</code></li></ul><pre><code>initContainers:
- name: volume-mount
  image: busybox
  command: [&quot;sh&quot;, &quot;-c&quot;, &quot;chown -R 100:100 /data&quot;]
  volumeMounts:
  - name: &lt;your data volume&gt;
    mountPath: /data
</code></pre><h2 id=8-addition-of-a-blob-based-disk-to-vm-with-managed-disks-is-not-supported>8. <code>Addition of a blob based disk to VM with managed disks is not supported</code></h2><p><strong>Issue details</strong>:</p><p>Following error may occur if attach a blob based(unmanaged) disk to VM with managed disks:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>  Warning  FailedMount            42s <span style=color:#ce5c00;font-weight:700>(</span>x2 over 1m<span style=color:#ce5c00;font-weight:700>)</span>  attachdetach                    AttachVolume.Attach failed <span style=color:#204a87;font-weight:700>for</span> volume <span style=color:#4e9a06>&#34;pvc-f17e5e77-474e-11e8-a2ea-000d3a10df6d&#34;</span> : Attach volume <span style=color:#4e9a06>&#34;holo-k8s-dev-dynamic-pvc-f17e5e77-474e-11e8-a2ea-000d3a10df6d&#34;</span> to instance <span style=color:#4e9a06>&#34;k8s-master-92699158-0&#34;</span> failed with compute.VirtualMachinesClient#CreateOrUpdate: Failure responding to request: <span style=color:#000>StatusCode</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>409</span> -- Original Error: autorest/azure: Service returned an error. <span style=color:#000>Status</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>409</span> <span style=color:#000>Code</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;OperationNotAllowed&#34;</span> <span style=color:#000>Message</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;Addition of a blob based disk to VM with managed disks is not supported.&#34;</span>
</code></pre></div><p>This issue is by design as in Azure, there are two kinds of disks, blob based(unmanaged) disk and managed disk, an Azure VM could not attach both of these two kinds of disks.</p><p><strong>Solution</strong>:</p><p>Use <code>default</code> azure disk storage class in aks-engine, as <code>default</code> will always be identical to the agent pool, that is, if VM is managed, it will be managed azure disk class, if unmanaged, then it's unmanaged disk class.</p><h2 id=9-dynamic-azure-disk-pvc-try-to-access-wrong-storage-account-of-other-resource-group>9. dynamic azure disk PVC try to access wrong storage account (of other resource group)</h2><p><strong>Issue details</strong>:</p><p>In a k8s cluster with <strong>blob based</strong> VMs(won't happen in AKS since AKS only use managed disk), create dynamic azure disk PVC may fail, error logs is like following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>Failed to provision volume with StorageClass <span style=color:#4e9a06>&#34;default&#34;</span>: azureDisk - account ds6c822a4d484211eXXXXXX does not exist <span style=color:#204a87;font-weight:700>while</span> trying to create/ensure default container
</code></pre></div><p><strong>Related issues</strong></p><ul><li><a href=https://github.com/Azure/acs-engine/issues/2768>Multiple clusters - dynamic PVCs try to access wrong storage account (of other resource group)</a></li></ul><p><strong>Fix</strong></p><ul><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/56474>fix storage account not found issue: use ListByResourceGroup instead of List()</a> fixed this issue</li></ul><table><thead><tr><th>k8s version</th><th>fixed version</th></tr></thead><tbody><tr><td>v1.8</td><td>1.8.13</td></tr><tr><td>v1.9</td><td>1.9.9</td></tr><tr><td>v1.10</td><td>no such issue</td></tr></tbody></table><p><strong>Work around</strong>:</p><p>this bug only exists in blob based VM in v1.8.x, v1.9.x, so if specify <code>ManagedDisks</code> when creating k8s cluster in aks-engine(AKS is using managed disk by default), it won't have this issue:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json>    <span style=color:#4e9a06>&#34;agentPoolProfiles&#34;</span><span style=color:#a40000>:</span> <span style=color:#000;font-weight:700>[</span>
      <span style=color:#000;font-weight:700>{</span>
        <span style=color:#a40000>.</span><span style=color:#a40000>.</span><span style=color:#a40000>.</span>
        <span style=color:#204a87;font-weight:700>&#34;storageProfile&#34;</span> <span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;ManagedDisks&#34;</span><span style=color:#000;font-weight:700>,</span>
        <span style=color:#a40000>.</span><span style=color:#a40000>.</span><span style=color:#a40000>.</span>
      <span style=color:#000;font-weight:700>}</span>
</code></pre></div><h2 id=10-data-loss-if-using-existing-azure-disk-with-partitions-in-disk-mount>10. data loss if using existing azure disk with partitions in disk mount</h2><p><strong>Issue details</strong>:</p><p>When use an existing azure disk(also called <a href=https://github.com/andyzhangx/demo/tree/master/linux/azuredisk#static-provisioning-for-azure-disk>static provisioning</a>) in pod, if that disk has partitions, the disk will be formatted in the pod mounting process, actually k8s volume don't support mount disk with partitions, disk mount would fail finally. While for mounting existing <strong>azure</strong> disk that has partitions, data will be lost since it will format that disk first. This issue happens only on <strong>Linux</strong>.</p><p><strong>Related issues</strong></p><ul><li><a href=https://github.com/kubernetes/kubernetes/issues/63235>data loss if using existing azure disk with partitions in disk mount</a></li></ul><p><strong>Fix</strong></p><ul><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/63270>fix data loss issue if using existing azure disk with partitions in disk mount</a> will let azure provider return error when mounting existing azure disk that has partitions</li></ul><table><thead><tr><th>k8s version</th><th>fixed version</th></tr></thead><tbody><tr><td>v1.8</td><td>1.8.15</td></tr><tr><td>v1.9</td><td>1.9.11</td></tr><tr><td>v1.10</td><td>1.10.5</td></tr><tr><td>v1.11</td><td>1.11.0</td></tr></tbody></table><p><strong>Work around</strong>:</p><p>Don't use existing azure disk that has partitions, e.g. following disk in LUN 0 that has one partition:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>azureuser@aks-nodepool1-28371372-0:/$ ls -l /dev/disk/azure/scsi1/
total <span style=color:#0000cf;font-weight:700>0</span>
lrwxrwxrwx <span style=color:#0000cf;font-weight:700>1</span> root root <span style=color:#0000cf;font-weight:700>12</span> Apr <span style=color:#0000cf;font-weight:700>27</span> 08:04 lun0 -&gt; ../../../sdc
lrwxrwxrwx <span style=color:#0000cf;font-weight:700>1</span> root root <span style=color:#0000cf;font-weight:700>13</span> Apr <span style=color:#0000cf;font-weight:700>27</span> 08:04 lun0-part1 -&gt; ../../../sdc1
</code></pre></div><h2 id=11-delete-azure-disk-pvc-which-is-already-in-use-by-a-pod>11. Delete azure disk PVC which is already in use by a pod</h2><p><strong>Issue details</strong>:</p><p>Following error may occur if delete azure disk PVC which is already in use by a pod:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>kubectl describe pv pvc-d8eebc1d-74d3-11e8-902b-e22b71bb1c06
...
Message:         disk.DisksClient#Delete: Failure responding to request: <span style=color:#000>StatusCode</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>409</span> -- Original Error: autorest/azure: Service returned an error. <span style=color:#000>Status</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>409</span> <span style=color:#000>Code</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;OperationNotAllowed&#34;</span> <span style=color:#000>Message</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;Disk kubernetes-dynamic-pvc-d8eebc1d-74d3-11e8-902b-e22b71bb1c06 is attached to VM /subscriptions/{subs-id}/resourceGroups/MC_markito-aks-pvc_markito-aks-pvc_westus/providers/Microsoft.Compute/virtualMachines/aks-agentpool-25259074-0.&#34;</span>
</code></pre></div><p><strong>Fix</strong>:</p><p>This is a common k8s issue, other cloud provider would also has this issue. There is a <a href=https://kubernetes.io/docs/tasks/administer-cluster/pvc-protection/>PVC protection</a> feature to prevent this, it's alpha in v1.9, and beta(enabled by default) in v1.10</p><p><strong>Work around</strong>:
delete pod first and then delete azure disk pvc after a few minutes</p><h2 id=12-create-azure-disk-pvc-failed-due-to-account-creation-failure>12. create azure disk PVC failed due to account creation failure</h2><blockquote><p>please note this issue only happens on <strong>unmanaged</strong> k8s cluster</p></blockquote><p><strong>Issue details</strong>: User may get <code>Account property kind is invalid for the request</code> error when trying to create a new <strong>unmanaged</strong> azure disk PVC, error would be like following:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>azureuser@k8s-master-17140924-0:/tmp$ kubectl describe pvc
Name:          pvc-azuredisk
Namespace:     default
StorageClass:  hdd
Status:        Bound
...
Events:
  Type     Reason                 Age                From                         Message
  ----     ------                 ----               ----                         -------
  Warning  ProvisioningFailed     31m                persistentvolume-controller  Failed to provision volume with StorageClass <span style=color:#4e9a06>&#34;hdd&#34;</span>: Create Storage Account: ds10e15ed89c5811e8a0a70, error: storage.AccountsClient#Create: Failure sending request: <span style=color:#000>StatusCode</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>400</span> -- Original Error: <span style=color:#000>Code</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;AccountPropertyIsInvalid&#34;</span> <span style=color:#000>Message</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#34;Account property kind is invalid for the request.&#34;</span>
</code></pre></div><p><strong>Fix</strong></p><ul><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/67236>fix azure disk create failure due to sdk upgrade</a> fixed this issue</li></ul><table><thead><tr><th>k8s version</th><th>fixed version</th></tr></thead><tbody><tr><td>v1.9</td><td>no such issue</td></tr><tr><td>v1.10</td><td>no such issue</td></tr><tr><td>v1.11</td><td>1.11.3</td></tr><tr><td>v1.12</td><td>no such issue</td></tr></tbody></table><p><strong>Work around</strong>:</p><ul><li>create a storage account and specify that account in azure disk storage class, e.g.</li></ul><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>kind<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>StorageClass<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span>apiVersion<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>storage.k8s.io/v1beta1<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span>metadata<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span>name<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>ssd<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span>provisioner<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>kubernetes.io/azure-disk<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span>parameters<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span>skuname<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>Premium_LRS<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span>storageAccount<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>customerstorageaccount<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span>kind<span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>Dedicated<span style=color:#f8f8f8;text-decoration:underline>
</span></code></pre></div><h2 id=13-cannot-find-lun-for-disk>13. cannot find Lun for disk</h2><p><strong>Issue details</strong>:</p><p>Following error may occur if attach a disk to a node:</p><pre><code>MountVolume.WaitForAttach failed for volume &quot;pvc-12b458f4-c23f-11e8-8d27-46799c22b7c6&quot; : Cannot find Lun for disk kubernetes-dynamic-pvc-12b458f4-c23f-11e8-8d27-46799c22b7c6
</code></pre><p><strong>Related issues</strong></p><ul><li><a href=https://github.com/kubernetes/kubernetes/issues/69262>GetAzureDiskLun sometimes costs 1 min which is too long time</a></li></ul><p><strong>Fix</strong></p><ul><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/70002>fix azure disk attachment error on Linux</a> will extract the LUN num from device path <strong>only on Linux</strong></li></ul><table><thead><tr><th>k8s version</th><th>fixed version</th></tr></thead><tbody><tr><td>v1.9</td><td>no such issue</td></tr><tr><td>v1.10</td><td>1.10.10</td></tr><tr><td>v1.11</td><td>1.11.5</td></tr><tr><td>v1.12</td><td>1.12.3</td></tr><tr><td>v1.13</td><td>no such issue</td></tr></tbody></table><p><strong>Work around</strong>:</p><p>wait for a few more minutes should work</p><h2 id=14-azure-disk-attachdetach-failure-mount-issue-io-error>14. azure disk attach/detach failure, mount issue, i/o error</h2><p><strong>Issue details</strong>:</p><p>We found a disk attach/detach issue due to <a href=https://github.com/kubernetes/kubernetes/pull/58313>dirty vm cache PR</a> introduced from v1.9.2, it would lead to following disk issues:</p><ul><li>disk attach/detach failure for a long time</li><li>disk I/O error</li><li>unexpected disk detachment from VM</li><li>VM running into failed state due to attaching non-existing disk</li></ul><blockquote><p>Note: above error may <strong>only</strong> happen when there are multiple disk attach/detach operations in parallel and it's not easy to repro since it happens on a little possibility.</p></blockquote><p><strong>Related issues</strong></p><ul><li><a href=https://github.com/kubernetes/kubernetes/issues/71344>Azure Disks volume attach still times out on Kubernetes 1.10</a></li><li><a href=https://github.com/kubernetes/kubernetes/issues/71453>Azure Disks occasionally mounted in a way leading to I/O errors</a></li></ul><p><strong>Fix</strong></p><p>We changed the azure disk attach/detach retry logic in k8s v1.13, switch to use k8s attach-detach controller to do attach/detach disk retry and clean vm cache after every disk operation, this issue is proved to be fixed in our disk attach/detach stress test and also verified in customer env:</p><ul><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/70568>remove retry operation on attach/detach azure disk in azure cloud provider</a></li><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/71377>fix azure disk attach/detach failed forever issue</a></li><li>PR <a href=https://github.com/kubernetes/kubernetes/pull/71495>fix detach azure disk issue due to dirty cache</a></li></ul><table><thead><tr><th>k8s version</th><th>fixed version</th></tr></thead><tbody><tr><td>v1.9</td><td>issue introduced in v1.9.2, no cherry-pick fix allowed</td></tr><tr><td>v1.10</td><td>1.10.12</td></tr><tr><td>v1.11</td><td>1.11.6</td></tr><tr><td>v1.12</td><td>1.12.4</td></tr><tr><td>v1.13</td><td>no such issue</td></tr></tbody></table><p><strong>Work around</strong>:</p><ul><li>if there is attach disk failure for long time, restart controller manager may work</li><li>if there is disk not detached for long time, detach that disk manually</li></ul><style>.feedback--answer{display:inline-block}.feedback--answer-no{margin-left:1em}.feedback--response{display:none;margin-top:1em}.feedback--response__visible{display:block}</style><h2 class=feedback--title>Feedback</h2><p class=feedback--question>Was this page helpful?</p><button class="feedback--answer feedback--answer-yes">Yes</button>
<button class="feedback--answer feedback--answer-no">No</button><p class="feedback--response feedback--response-yes">Glad to hear it! Please <a href=https://github.com/USERNAME/REPOSITORY/issues/new>tell us how we can improve</a>.</p><p class="feedback--response feedback--response-no">Sorry to hear that. Please <a href=https://github.com/USERNAME/REPOSITORY/issues/new>tell us how we can improve</a>.</p><script>const yesButton=document.querySelector('.feedback--answer-yes');const noButton=document.querySelector('.feedback--answer-no');const yesResponse=document.querySelector('.feedback--response-yes');const noResponse=document.querySelector('.feedback--response-no');const disableButtons=()=>{yesButton.disabled=true;noButton.disabled=true;};const sendFeedback=(value)=>{if(typeof ga!=='function')return;const args={command:'send',hitType:'event',category:'Helpful',action:'click',label:window.location.pathname,value:value};ga(args.command,args.hitType,args.category,args.action,args.label,args.value);};yesButton.addEventListener('click',()=>{yesResponse.classList.add('feedback--response__visible');disableButtons();sendFeedback(1);});noButton.addEventListener('click',()=>{noResponse.classList.add('feedback--response__visible');disableButtons();sendFeedback(0);});</script><br><div class="text-muted mt-5 pt-3 border-top">Last modified August 26, 2020: <a href=https://github.com/kubernetes-sigs/azuredisk-csi-driver/commit/65abbd9ec8cac532a7c74124f013eed3224c1531>feat: Deploy github-page for AzureDisk CSI Driver. (65abbd9e)</a></div></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Google Group" aria-label="Google Group"><a class=text-white target=_blank href=https://groups.google.com/forum/#!forum/kubernetes-sig-cloud-provider><i class="fa fa-envelope"></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes-sigs/azuredisk-csi-driver><i class="fab fa-github"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2020 The Kubernetes Authors All Rights Reserved</small></div></div></div></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js integrity=sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49 crossorigin=anonymous></script><script src=https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js integrity=sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy crossorigin=anonymous></script><script src=/azuredisk-csi-driver/js/main.min.664f21bf5eb0c31ebc661e2616e6c63e0448cec6d5636d869957be423c3cb952.js integrity="sha256-Zk8hv16wwx68Zh4mFubGPgRIzsbVY22GmVe+Qjw8uVI=" crossorigin=anonymous></script></body></html>